{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForQuestionAnswering,\n    TrainingArguments,\n    Trainer,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:44:40.715141Z","iopub.execute_input":"2024-12-06T11:44:40.715438Z","iopub.status.idle":"2024-12-06T11:45:01.668892Z","shell.execute_reply.started":"2024-12-06T11:44:40.715410Z","shell.execute_reply":"2024-12-06T11:45:01.667969Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"dataset = load_dataset(\"squad_v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:45:01.670477Z","iopub.execute_input":"2024-12-06T11:45:01.671177Z","iopub.status.idle":"2024-12-06T11:45:04.191801Z","shell.execute_reply.started":"2024-12-06T11:45:01.671136Z","shell.execute_reply":"2024-12-06T11:45:04.191149Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"575c588b85484dd996ce0ff927d70fc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64bf8572a0324d478397a8c42904a806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd194b0134bf41f6891d0ceec9766ea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7368a579707d424c8bc322e3efcdce09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ebc106a0f4e4b6aa6e5dba7aa99665a"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"model_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:00:37.752814Z","iopub.execute_input":"2024-12-04T19:00:37.753448Z","iopub.status.idle":"2024-12-04T19:00:40.407301Z","shell.execute_reply.started":"2024-12-04T19:00:37.753411Z","shell.execute_reply":"2024-12-04T19:00:40.406481Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96ee87c9c5d444d288c39c197358d3fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea000162fa694c83b3f69e6ed64ea48d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc1fcaa249894c82937c389302f734e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e145b4c27f5a4e3a8a2a9ef0d5cef508"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"925e6d16914e488b80854b116aa98078"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 3. Preprocess the data\nmax_length = 512  # Maximum length of input sequences\ndoc_stride = 128  # Helps in splitting long documents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:00:44.121550Z","iopub.execute_input":"2024-12-04T19:00:44.121893Z","iopub.status.idle":"2024-12-04T19:00:44.126067Z","shell.execute_reply.started":"2024-12-04T19:00:44.121863Z","shell.execute_reply":"2024-12-04T19:00:44.125167Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def preprocess_data(examples):\n    # Tokenize the questions and context\n    encoding = tokenizer(\n        examples['question'],\n        examples['context'],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_tensors=\"pt\"\n    )\n\n    # Find the start and end positions of the answer in the context\n    start_positions = []\n    end_positions = []\n\n    for context, answer in zip(examples['context'], examples['answers']):\n        if len(answer['text']) > 0:\n            # Get the text of the first answer (assuming one answer per question)\n            answer_text = answer['text'][0]\n            start_position = context.find(answer_text)\n            \n            # Ensure the answer exists in the context\n            if start_position != -1:\n                end_position = start_position + len(answer_text) - 1\n            else:\n                start_position = 0\n                end_position = 0\n        else:\n            # No valid answer\n            start_position = 0\n            end_position = 0\n\n        start_positions.append(start_position)\n        end_positions.append(end_position)\n\n    # Add start and end positions to the encoding\n    encoding['start_positions'] = start_positions\n    encoding['end_positions'] = end_positions\n\n    return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:00:47.882450Z","iopub.execute_input":"2024-12-04T19:00:47.882802Z","iopub.status.idle":"2024-12-04T19:00:47.889365Z","shell.execute_reply.started":"2024-12-04T19:00:47.882770Z","shell.execute_reply":"2024-12-04T19:00:47.888452Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Preprocess both train and validation datasets\ntrain_dataset = dataset[\"train\"].map(preprocess_data, batched=True)\nval_dataset = dataset[\"validation\"].map(preprocess_data, batched=True)\n\n# Remove unnecessary columns after processing\ntrain_dataset = train_dataset.remove_columns([\"question\", \"context\"])\nval_dataset = val_dataset.remove_columns([\"question\", \"context\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:00:54.944475Z","iopub.execute_input":"2024-12-04T19:00:54.944820Z","iopub.status.idle":"2024-12-04T19:02:00.172860Z","shell.execute_reply.started":"2024-12-04T19:00:54.944791Z","shell.execute_reply":"2024-12-04T19:02:00.172200Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1a26900a2be479e983aef93e4aaefcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb89cdff2ae43e2add82ac917487005"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./distilbert-qa\",        # Directory to store the model\n    evaluation_strategy=\"epoch\",         # Evaluate at the end of each epoch\n    learning_rate=2e-5,                  # Learning rate for fine-tuning\n    per_device_train_batch_size=8,       # Adjust to fit your GPU memory\n    per_device_eval_batch_size=8,        # Same as above for evaluation\n    num_train_epochs=3,                  # Number of training epochs\n    save_strategy=\"epoch\",               # Save model at the end of each epoch\n    save_total_limit=2,                  # Limit the number of saved models\n    fp16=True,                           # Enable mixed precision for faster training\n    logging_dir=\"./logs\",                # Directory for logging\n    logging_steps=100,                   # Log every 100 steps\n    report_to=\"none\",                   # Avoid using default WandB or TensorBoard\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:02:05.047399Z","iopub.execute_input":"2024-12-04T19:02:05.047761Z","iopub.status.idle":"2024-12-04T19:02:05.193340Z","shell.execute_reply.started":"2024-12-04T19:02:05.047731Z","shell.execute_reply":"2024-12-04T19:02:05.192447Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# 5. Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:02:08.361437Z","iopub.execute_input":"2024-12-04T19:02:08.362082Z","iopub.status.idle":"2024-12-04T19:02:08.867574Z","shell.execute_reply.started":"2024-12-04T19:02:08.362048Z","shell.execute_reply":"2024-12-04T19:02:08.866812Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2415645228.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:02:17.033802Z","iopub.execute_input":"2024-12-04T19:02:17.034788Z","iopub.status.idle":"2024-12-04T22:14:07.811100Z","shell.execute_reply.started":"2024-12-04T19:02:17.034750Z","shell.execute_reply":"2024-12-04T22:14:07.810077Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24435' max='24435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24435/24435 3:11:48, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.670500</td>\n      <td>2.979045</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.410200</td>\n      <td>2.904812</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.207600</td>\n      <td>2.943974</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=24435, training_loss=3.5678972463215546, metrics={'train_runtime': 11510.4471, 'train_samples_per_second': 33.965, 'train_steps_per_second': 2.123, 'total_flos': 5.107974402921062e+16, 'train_loss': 3.5678972463215546, 'epoch': 3.0})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Evaluate the model on the validation dataset\neval_results = trainer.evaluate()\n\nprint(\"Evaluation Results:\")\nfor key, value in eval_results.items():\n    print(f\"{key}: {value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:14:43.453513Z","iopub.execute_input":"2024-12-04T22:14:43.453847Z","iopub.status.idle":"2024-12-04T22:16:28.840468Z","shell.execute_reply.started":"2024-12-04T22:14:43.453819Z","shell.execute_reply":"2024-12-04T22:16:28.839723Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='743' max='743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [743/743 01:45]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results:\neval_loss: 2.943974018096924\neval_runtime: 105.378\neval_samples_per_second: 112.671\neval_steps_per_second: 7.051\nepoch: 3.0\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"inputs = tokenizer(\n    test_data[\"question\"],\n    test_data[\"context\"],\n    truncation=True,\n    padding=\"max_length\",\n    max_length=max_length,\n    return_tensors=\"pt\"\n).to(\"cuda\")  # Send the data to GPU if available","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:17:19.757523Z","iopub.execute_input":"2024-12-04T22:17:19.757867Z","iopub.status.idle":"2024-12-04T22:17:19.763323Z","shell.execute_reply.started":"2024-12-04T22:17:19.757836Z","shell.execute_reply":"2024-12-04T22:17:19.762437Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Get the model's predictions\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():\n    outputs = model(**inputs)\n\n# Extract the start and end logits\nstart_logits = outputs.start_logits\nend_logits = outputs.end_logits\n\n# Get the most probable start and end positions\nstart_index = torch.argmax(start_logits, dim=1).item()\nend_index = torch.argmax(end_logits, dim=1).item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:17:26.977968Z","iopub.execute_input":"2024-12-04T22:17:26.978719Z","iopub.status.idle":"2024-12-04T22:17:27.008287Z","shell.execute_reply.started":"2024-12-04T22:17:26.978681Z","shell.execute_reply":"2024-12-04T22:17:27.007644Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model.save_pretrained(\"./fine_tuned_distilbert\")\ntokenizer.save_pretrained(\"./fine_tuned_distilbert\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:18:13.825204Z","iopub.execute_input":"2024-12-04T22:18:13.825656Z","iopub.status.idle":"2024-12-04T22:18:14.462252Z","shell.execute_reply.started":"2024-12-04T22:18:13.825620Z","shell.execute_reply":"2024-12-04T22:18:14.461428Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_distilbert/tokenizer_config.json',\n './fine_tuned_distilbert/special_tokens_map.json',\n './fine_tuned_distilbert/vocab.txt',\n './fine_tuned_distilbert/added_tokens.json',\n './fine_tuned_distilbert/tokenizer.json')"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n\nmodel_path = \"./fine_tuned_distilbert\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_path).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:18:30.550125Z","iopub.execute_input":"2024-12-04T22:18:30.550501Z","iopub.status.idle":"2024-12-04T22:18:30.690836Z","shell.execute_reply.started":"2024-12-04T22:18:30.550469Z","shell.execute_reply":"2024-12-04T22:18:30.690149Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def answer_question(question, context):\n    # Tokenize the inputs\n    inputs = tokenizer(\n        question,\n        context,\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512,\n        return_tensors=\"pt\"\n    ).to(\"cuda\")  # Send to GPU if available\n\n    # Get model predictions\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Extract start and end logits\n    start_logits = outputs.start_logits\n    end_logits = outputs.end_logits\n\n    # Find the most probable start and end positions of the answer\n    start_index = torch.argmax(start_logits, dim=1).item()\n    end_index = torch.argmax(end_logits, dim=1).item()\n\n    # Handle cases where the model predicts no answer\n    if start_index >= end_index or start_index < 0 or end_index < 0:\n        return \"No answer found.\"\n\n    # Decode the answer from the token indices\n    tokens = inputs[\"input_ids\"][0]\n    answer_tokens = tokens[start_index : end_index + 1]\n    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n\n    return answer\n\n# Example usage\nquestion = \"When did Beyonce start becoming popular?\"\ncontext = 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\"'\n\nanswer = answer_question(question, context)\nprint(f\"Question: {question}\")\nprint(f\"Answer: {answer}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}